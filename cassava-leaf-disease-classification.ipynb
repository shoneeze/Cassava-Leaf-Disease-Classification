{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13836,"databundleVersionId":1718836,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Section 1: Imports and Configuration\n### Importing necessary libraries for data manipulation, visualization, and model building.","metadata":{}},{"cell_type":"code","source":"# Cassava Leaf Disease Classification\n\n## Overview\n# This notebook implements a classification model using EfficientNetB0 to detect leaf diseases from cassava images. The dataset contains five disease classes.\n\n# Section 1: Imports and Configuration\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.utils.class_weight import compute_class_weight\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport os\nfrom PIL import Image\n\n# Configuration settings\nclass CFG:    \n    WORK_DIR = \"../input/cassava-leaf-disease-classification/\"\n    BATCH_SIZE = 8\n    EPOCHS = 10\n    TARGET_SIZE = 256\n    NCLASSES = 5\n\n# Utility functions\ndef visualize_class_distribution(labels):\n    plt.figure(figsize=(8, 6))\n    sns.countplot(x='label', data=labels, palette='coolwarm')\n    plt.title('Class Distribution', fontsize=16)\n    plt.xlabel('Disease Classes', fontsize=14)\n    plt.ylabel('Frequency', fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\ndef load_and_display_sample_image(image_dir, image_id, label):\n    sample_image_path = os.path.join(image_dir, image_id)\n    sample_image = Image.open(sample_image_path)\n    plt.figure(figsize=(6, 6))\n    plt.imshow(sample_image)\n    plt.title(f\"Sample Image - Class: {label}\")\n    plt.axis('off')\n    plt.show()\n\ndef create_data_generators(labels, image_dir):\n    train_datagen = ImageDataGenerator(\n        validation_split=0.2,\n        rescale=1./255,\n        rotation_range=45,\n        zoom_range=0.2,\n        shear_range=0.15,\n        brightness_range=[0.8, 1.2],\n        channel_shift_range=50.0,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest'\n    )\n\n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=labels,\n        directory=image_dir,\n        subset=\"training\",\n        x_col=\"image_id\",\n        y_col=\"label\",\n        target_size=(CFG.TARGET_SIZE, CFG.TARGET_SIZE),\n        batch_size=CFG.BATCH_SIZE,\n        class_mode=\"sparse\",\n        seed=42\n    )\n\n    validation_datagen = ImageDataGenerator(\n        validation_split=0.2,\n        rescale=1./255\n    )\n\n    validation_generator = validation_datagen.flow_from_dataframe(\n        dataframe=labels,\n        directory=image_dir,\n        subset=\"validation\",\n        x_col=\"image_id\",\n        y_col=\"label\",\n        target_size=(CFG.TARGET_SIZE, CFG.TARGET_SIZE),\n        batch_size=CFG.BATCH_SIZE,\n        class_mode=\"sparse\",\n        seed=42\n    )\n\n    return train_generator, validation_generator\n\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy', fontsize=16)\n    plt.xlabel('Epochs', fontsize=14)\n    plt.ylabel('Accuracy', fontsize=14)\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss', fontsize=16)\n    plt.xlabel('Epochs', fontsize=14)\n    plt.ylabel('Loss', fontsize=14)\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\ndef evaluate_model(model, generator, class_indices):\n    val_preds = model.predict(generator).argmax(axis=1)\n    val_true = generator.classes\n\n    # Classification report\n    report = classification_report(val_true, val_preds, target_names=class_indices.keys())\n    print(report)\n\n    # Confusion matrix\n    cm = confusion_matrix(val_true, val_preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_indices.keys(), yticklabels=class_indices.keys())\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    return val_preds, val_true\n\ndef plot_roc_curve(model, generator, class_indices):\n    val_true_bin = label_binarize(generator.classes, classes=list(class_indices.values()))\n    pred_probs = model.predict(generator)\n\n    plt.figure(figsize=(10, 8))\n    for i, class_name in enumerate(class_indices.keys()):\n        fpr, tpr, _ = roc_curve(val_true_bin[:, i], pred_probs[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.title('Multi-Class ROC Curve', fontsize=16)\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n    plt.legend()\n    plt.grid()\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 2: Load and Explore Data\n### Load the dataset and explore its structure to understand the data.","metadata":{}},{"cell_type":"code","source":"\ntrain_labels = pd.read_csv(os.path.join(CFG.WORK_DIR, \"train.csv\"))\ntrain_labels['label'] = train_labels['label'].astype(str)\n\n# Visualize class distribution\nvisualize_class_distribution(train_labels)\n\n# Display sample image\nimage_dir = os.path.join(CFG.WORK_DIR, \"train_images\")\nload_and_display_sample_image(image_dir, train_labels['image_id'][0], train_labels['label'][0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 3: Data Preprocessing\n### Preprocessing includes normalizing pixel values and augmenting the dataset to improve model generalization.","metadata":{}},{"cell_type":"code","source":"train_generator, validation_generator = create_data_generators(train_labels, image_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 4: Model Creation\n### Define the EfficientNetB0 model architecture and prepare it for training.","metadata":{}},{"cell_type":"code","source":"# Section 4: Model Creation\ndef create_model():\n    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(CFG.TARGET_SIZE, CFG.TARGET_SIZE, 3))\n    x = layers.GlobalAveragePooling2D()(base_model.output)\n    x = layers.Dropout(0.5)(x)\n    output = layers.Dense(CFG.NCLASSES, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    model = models.Model(inputs=base_model.input, outputs=output)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nmodel = create_model()\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels['label']), y=train_labels['label'])\nclass_weights = dict(enumerate(class_weights))\nprint(\"Class Weights:\", class_weights)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 5: Model Training\n### Train the model using the training and validation data generators.","metadata":{}},{"cell_type":"code","source":"# Section 5: Model Training\ncallbacks = [\n    ModelCheckpoint('best_model.weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min',verbose = 1),\n    EarlyStopping(monitor='val_loss',min_delta = 0.001, patience=5,mode = 'min',verbose = 1, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2,min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n]\n\nSTEPS_PER_EPOCH = int(len(train_labels)*0.8 / CFG.BATCH_SIZE)\nVALIDATION_STEPS = int(len(train_labels)*0.2 / CFG.BATCH_SIZE)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    epochs=CFG.EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=VALIDATION_STEPS,\n    class_weight=class_weights,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 6: Model Evaluation and Predictions\n### Evaluate the trained model and make predictions on the test data.","metadata":{}},{"cell_type":"code","source":"# Section 6: Evaluation and Metrics\nval_preds, val_true = evaluate_model(model, validation_generator, validation_generator.class_indices)\nplot_roc_curve(model, validation_generator, validation_generator.class_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}